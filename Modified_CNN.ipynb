{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Draw Modified CNN\n",
    "Abel Tadesse <br />\n",
    "Jason Yi <br />\n",
    "Richy Chen <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "376d2827a7f11e80f6591bfc439a9d5558ef10fc"
   },
   "source": [
    "How the training data looks: The data frame is a concatenation of 2 rows from each CSV file in the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5090c701f9121207b67e13a0ae3f239514dff217",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ac7176e5826b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/train_simplified/*.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'countrycode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'drawing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'key_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recognized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrawlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# make sure we get a recognized drawing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "fnames = glob('../input/train_simplified/*.csv')\n",
    "cnames = ['countrycode', 'drawing', 'key_id', 'recognized', 'timestamp', 'word']\n",
    "drawlist = []\n",
    "for f in fnames[0:6]:\n",
    "    first = pd.read_csv(f, nrows=10) # make sure we get a recognized drawing\n",
    "    first = first[first.recognized==True].head(2)\n",
    "    drawlist.append(first)\n",
    "draw_df = pd.DataFrame(np.concatenate(drawlist), columns=cnames)\n",
    "draw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how the sketches look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2be57621533d0e0aa75108febde01261d2444c37"
   },
   "outputs": [],
   "source": [
    "evens = range(0,11,2)\n",
    "odds = range(1,12, 2)\n",
    "df1 = draw_df[draw_df.index.isin(evens)]\n",
    "df2 = draw_df[draw_df.index.isin(odds)]\n",
    "\n",
    "example1s = [ast.literal_eval(pts) for pts in df1.drawing.values]\n",
    "example2s = [ast.literal_eval(pts) for pts in df2.drawing.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0a1aaca9129ad3748e597993c90ab65c5fdefd5b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = df2.word.tolist()\n",
    "for i, example in enumerate(example1s):\n",
    "    plt.figure(figsize=(6,3))\n",
    "    \n",
    "    for x,y in example:\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(x, y, marker='.')\n",
    "        plt.axis('off')\n",
    "\n",
    "    for x,y, in example2s[i]:\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(x, y, marker='.')\n",
    "        plt.axis('off')\n",
    "        label = labels[i]\n",
    "        plt.title(label, fontsize=10)\n",
    "\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8b9f5b85771add0d7672f7611a62e4668a28453c"
   },
   "source": [
    "## Convolutional Neural Network (CNN) Implementation\n",
    "Essentially an image classifier. Interprets the data as a 2D object with the strokes at completion. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "adc697e3e58ef810c0576614ae95fa889bfb3345"
   },
   "outputs": [],
   "source": [
    "%reset -f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "779113b4b0ef5fbe50ddda59813b019b3b769b58"
   },
   "outputs": [],
   "source": [
    "#%% import\n",
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "import ast\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw \n",
    "from tqdm import tqdm\n",
    "from dask import bag\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "44e5965471a53f3ca6d87a1df8c0e1b2538cd34c"
   },
   "outputs": [],
   "source": [
    "#%% set label dictionary and params\n",
    "classfiles = os.listdir('../input/train_simplified/')\n",
    "numstonames = {i: v[:-4].replace(\" \", \"_\") for i, v in enumerate(classfiles)} #adds underscores\n",
    "\n",
    "num_classes = 50\n",
    "imheight, imwidth = 32, 32  \n",
    "ims_per_class = 2000  #max?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "1ce1101eea3b2a0787c1dbe6b675e2a481802f67",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# faster conversion function\n",
    "# Use PIL to make it faster to draw images\n",
    "def draw_it(strokes):\n",
    "    image = Image.new(\"P\", (256,256), color=255)\n",
    "    image_draw = ImageDraw.Draw(image)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0])-1):\n",
    "            image_draw.line([stroke[0][i], \n",
    "                             stroke[1][i],\n",
    "                             stroke[0][i+1], \n",
    "                             stroke[1][i+1]],\n",
    "                            fill=0, width=5)\n",
    "    image = image.resize((imheight, imwidth))\n",
    "    return np.array(image)/255.\n",
    "\n",
    "#%% get train arrays\n",
    "# train = all drawings of that label\n",
    "# trainarray = array representation of all those drawings in the label\n",
    "# train_grand = list of list accumulator for all the array representations of drawings. \n",
    "train_grand = []\n",
    "class_paths = glob('../input/train_simplified/*.csv')\n",
    "for i,c in enumerate(tqdm(class_paths[0: num_classes])):\n",
    "    #look at drawing and recognized columns\n",
    "    train = pd.read_csv(c, usecols=['drawing', 'recognized'], nrows=ims_per_class*5//4)\n",
    "    train = train[train.recognized == True].head(ims_per_class)\n",
    "    # draws out the drawing values \n",
    "    imagebag = bag.from_sequence(train.drawing.values).map(draw_it) \n",
    "    # draw them at same time into np array\n",
    "    trainarray = np.array(imagebag.compute())  \n",
    "    trainarray = np.reshape(trainarray, (ims_per_class, -1))   \n",
    "    # has all the label names for that specific label\n",
    "    labelarray = np.full((train.shape[0], 1), i)\n",
    "    # merge the labels and the drawings at every iteration and then stick it in one huge array\n",
    "    trainarray = np.concatenate((labelarray, trainarray), axis=1)\n",
    "    train_grand.append(trainarray)\n",
    "    \n",
    "train_grand = np.array([train_grand.pop() for i in np.arange(num_classes)]) #less memory than np.concatenate\n",
    "train_grand = train_grand.reshape((-1, (imheight*imwidth+1)))\n",
    "\n",
    "del trainarray\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "6788c33f4a9dd552d473e3667387491c40dbfe4b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# memory-friendly alternative to train_test_split?\n",
    "# write the cut off point for splitting data between train and validation\n",
    "valfrac = 0.1\n",
    "cutpt = int(valfrac * train_grand.shape[0])\n",
    "\n",
    "# shuffle the train_grand randomly\n",
    "np.random.shuffle(train_grand)\n",
    "# train gets last 90% and validation gets first 10%\n",
    "# y represents the label (output) and the x represents the drawn image\n",
    "y_train, X_train = train_grand[cutpt: , 0], train_grand[cutpt: , 1:]\n",
    "y_val, X_val = train_grand[0:cutpt, 0], train_grand[0:cutpt, 1:] #validation set is recognized==True\n",
    "\n",
    "del train_grand\n",
    "\n",
    "# Encode labels with value between 0 and n_classes-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# reshape the drawings to pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], imheight, imwidth, 1)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "X_val = X_val.reshape(X_val.shape[0], imheight, imwidth, 1)\n",
    "\n",
    "print(y_train.shape, \"\\n\",\n",
    "      X_train.shape, \"\\n\",\n",
    "      y_val.shape, \"\\n\",\n",
    "      X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "002b62eec9f0b5c139c4c08f82476433ccc11026"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# begin with 2D convolutional error instead of dense layer to prevent loss of spatial information\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(imheight, imwidth, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dropout to account for possible overfitting\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "6464e84f6f0c7303110db9e26c74a5c90a0a9ab9"
   },
   "outputs": [],
   "source": [
    "def top_3_accuracy(x,y): \n",
    "    t3 = top_k_categorical_accuracy(x,y, 3)\n",
    "    return t3\n",
    "# save weights as you go and make checkpoint when value is better\n",
    "weight_path=\"./{}_weights.hdf5\".format('modified_cnn_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "# monitor validation loss\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n",
    "                                   verbose=1, mode='auto', min_delta=0.005, cooldown=5, min_lr=0.0001)\n",
    "earlystop = EarlyStopping(monitor='val_top_3_accuracy', mode='max', patience=5) \n",
    "# while training, make these calls\n",
    "callbacks = [reduceLROnPlat, earlystop, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "6464e84f6f0c7303110db9e26c74a5c90a0a9ab9"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "6464e84f6f0c7303110db9e26c74a5c90a0a9ab9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=X_train, y=y_train,\n",
    "          batch_size = 4096,\n",
    "          epochs = 100,\n",
    "          validation_data = (X_val, y_val),\n",
    "          callbacks = callbacks,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "77a93f7b81f813b468713f20cf6f0226b20335dd"
   },
   "outputs": [],
   "source": [
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3dbb81d002088c5cbd97f5f9185e920c3c0c229d"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4125359749cd237de207eca0ab62074431df8323"
   },
   "source": [
    "## Predictions on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "_uuid": "2828f46cdf053261a1435e6eca1a4aea55195273"
   },
   "outputs": [],
   "source": [
    "#%% get test set\n",
    "ttvlist = []\n",
    "reader = pd.read_csv('../input/test_simplified.csv', index_col=['key_id'],\n",
    "    chunksize=2048)\n",
    "for chunk in tqdm(reader, total=55):\n",
    "    imagebag = bag.from_sequence(chunk.drawing.values).map(draw_it)\n",
    "    testarray = np.array(imagebag.compute())\n",
    "    testarray = np.reshape(testarray, (testarray.shape[0], imheight, imwidth, 1))\n",
    "    testpreds = model.predict(testarray, verbose=0)\n",
    "    ttvs = np.argsort(-testpreds)[:, 0:3]  # top 3\n",
    "    ttvlist.append(ttvs)\n",
    "    \n",
    "ttvarray = np.concatenate(ttvlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "_uuid": "5c650c6f9a0ec6f99042e6132ffc4a25b2b2f0b3"
   },
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame({'first': ttvarray[:,0], 'second': ttvarray[:,1], 'third': ttvarray[:,2]})\n",
    "preds_df = preds_df.replace(numstonames)\n",
    "preds_df['words'] = preds_df['first'] + \" \" + preds_df['second'] + \" \" + preds_df['third']\n",
    "\n",
    "sub = pd.read_csv('../input/sample_submission.csv', index_col=['key_id'])\n",
    "sub['word'] = preds_df.words.values\n",
    "sub.to_csv('cnn_mod.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f75a34af14218daf6865999b19d2766b48f339a2"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not \n",
    "    x.startswith('_') and x not in sys.modules and x \n",
    "    not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
